{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bf26cf0-487f-4724-b0aa-39504fa37762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c60810a-f5cc-4040-b898-92604edd6c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/common/users/dm1487/legged_manipulation_data/rollout_data/set_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70a8deeb-15ff-42e2-8360-af04459c42f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pieces = sorted(glob(str(data_path/'*.npz')))\n",
    "idxs = np.arange(550, 1050)\n",
    "pieces = [all_pieces[i] for i in idxs]\n",
    "len(pieces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51180c24-5485-4ca1-98e4-dd769127616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_pad_trajectories(tensor, dones):\n",
    "    \"\"\" Splits trajectories at done indices. Then concatenates them and padds with zeros up to the length og the longest trajectory.\n",
    "    Returns masks corresponding to valid parts of the trajectories\n",
    "    Example: \n",
    "        Input: [ [a1, a2, a3, a4 | a5, a6],\n",
    "                 [b1, b2 | b3, b4, b5 | b6]\n",
    "                f]\n",
    "\n",
    "        Output:[ [a1, a2, a3, a4], | [  [True, True, True, True],\n",
    "                 [a5, a6, 0, 0],   |    [True, True, False, False],\n",
    "                 [b1, b2, 0, 0],   |    [True, True, False, False],\n",
    "                 [b3, b4, b5, 0],  |    [True, True, True, False],\n",
    "                 [b6, 0, 0, 0]     |    [True, False, False, False],\n",
    "                ]                  | ]    \n",
    "            \n",
    "    Assumes that the input has the following dimension order: [time, number of envs, aditional dimensions]\n",
    "    \"\"\"\n",
    "    # dones = dones.clone()\n",
    "    dones[-1] = 1\n",
    "    # Permute the buffers to have order (num_envs, num_transitions_per_env, ...), for correct reshaping\n",
    "    flat_dones = dones.transpose(1, 0).reshape(-1, 1)\n",
    "    # flat_dones = dones.reshape(-1, 1)\n",
    "\n",
    "    # Get length of trajectory by counting the number of successive not done elements\n",
    "    done_indices = torch.cat((flat_dones.new_tensor([-1], dtype=torch.int64), flat_dones.nonzero()[:, 0]))\n",
    "    trajectory_lengths = done_indices[1:] - done_indices[:-1]\n",
    "    trajectory_lengths_list = trajectory_lengths.tolist()\n",
    "    # Extract the individual trajectories\n",
    "    trajectories = torch.split(tensor.transpose(1, 0).flatten(0, 1),trajectory_lengths_list)\n",
    "    padded_trajectories = torch.nn.utils.rnn.pad_sequence(trajectories)\n",
    "    \n",
    "    trajectory_masks = trajectory_lengths > torch.arange(0, tensor.shape[0], device=tensor.device).unsqueeze(1)\n",
    "    \n",
    "    print(trajectory_masks.shape)\n",
    "    return padded_trajectories, trajectory_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24ca175f-de7d-4d0c-b273-2e043b1a534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['observations',\n",
       " 'privileged_observations',\n",
       " 'observation_histories',\n",
       " 'full_seen_world']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = list(np.load(pieces[0]).keys())\n",
    "keys = keys[:4]\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd351639-128c-4513-ab59-850ba865d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pieces(key):\n",
    "    tensor_pieces = []\n",
    "    done_pieces = []\n",
    "    start = 0\n",
    "    offset = 100\n",
    "    with tqdm(total=len(pieces)) as pbar:\n",
    "        while True:\n",
    "            tensor = None\n",
    "            if start >= len(pieces):\n",
    "                break\n",
    "            for p in pieces[start:start+offset]:\n",
    "                traj_dict = np.load(p)\n",
    "                if tensor is None:\n",
    "                    if key == \"observation_histories\":\n",
    "                        tensor = torch.tensor(traj_dict[key][:, :, -37:])\n",
    "                    else:\n",
    "                        tensor = torch.tensor(traj_dict[key])\n",
    "                    dones = torch.tensor(traj_dict['dones'], dtype=torch.bool)\n",
    "                    continue\n",
    "                \n",
    "                if key == \"observation_histories\":\n",
    "                    tensor = torch.cat([tensor, torch.tensor(traj_dict[key])[:, :, -37:]], dim=0)\n",
    "                else:\n",
    "                    tensor = torch.cat([tensor, torch.tensor(traj_dict[key])], dim=0)\n",
    "                dones = torch.cat([dones, torch.tensor(traj_dict['dones'], dtype=torch.bool)], dim=0)\n",
    "            tensor_pieces.append(tensor)\n",
    "            done_pieces.append(dones)\n",
    "            start += offset\n",
    "            pbar.update(offset)\n",
    "            \n",
    "        return tensor_pieces, done_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8a64da5-0b44-4019-81aa-5ad3a19fb8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:55<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:30<00:00,  5.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [09:22<00:00,  1.12s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [02:11<00:00,  3.81it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "tmp_path = Path(f'/common/users/dm1487/tmp/500_pieces_next')\n",
    "tmp_path.mkdir(parents=True, exist_ok=True)\n",
    "save_dones = False\n",
    "for key in keys:\n",
    "    a, d = get_pieces(key)\n",
    "    with open(tmp_path/f'{key}.pkl', 'wb') as f:\n",
    "        pickle.dump(a, f)\n",
    "    if not save_dones:\n",
    "        with open(tmp_path/f'dones.pkl', 'wb') as f:\n",
    "            pickle.dump(d, f)\n",
    "        print('done')\n",
    "        save_dones = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe73f3c1-0f2b-4432-ad62-26ca21e56328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_traj_and_save(name, tensor_pieces, done_pieces, ctr = 0):\n",
    "    DATA_PATH_TRAJ = Path(f'/common/users/dm1487/legged_manipulation_data/rollout_data/latest_trajectories_2/{name}')\n",
    "    DATA_PATH_TRAJ.mkdir(parents=True, exist_ok=True)\n",
    "    all_dones = torch.cat(done_pieces, dim=0)\n",
    "    all_tensor = torch.cat(tensor_pieces, dim=0)\n",
    "    all_tensor_traj = split_and_pad_trajectories(all_tensor, all_dones)\n",
    "    if name == 'dones':\n",
    "        traj = all_tensor_traj[1].permute(1, 0)\n",
    "    else:\n",
    "        traj = all_tensor_traj[0].permute(1, 0, 2)\n",
    "    start = 0\n",
    "    offset = 10000\n",
    "    with tqdm(total=traj.shape[0]) as pbar:\n",
    "        while True:\n",
    "            if start >= traj.shape[0]:\n",
    "                break\n",
    "\n",
    "            np.savez_compressed(DATA_PATH_TRAJ/f'{name}_{ctr}.npz', data=traj[start:start+offset])\n",
    "            start += offset\n",
    "            pbar.update(offset)\n",
    "            ctr += 1\n",
    "    return all_tensor_traj[1], ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d78fed4b-0083-431f-86f0-698cc80c3ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "done\n",
      "torch.Size([5000, 153316])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160000it [02:13, 1195.69it/s]                                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 155860])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160000it [03:27, 770.51it/s]                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "done\n",
      "torch.Size([5000, 153316])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160000it [01:38, 1627.73it/s]                                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 155860])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160000it [01:37, 1641.44it/s]                                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "done\n",
      "torch.Size([5000, 153316])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160000it [08:19, 320.40it/s]                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 155860])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160000it [07:50, 340.28it/s]                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "done\n",
      "torch.Size([5000, 153316])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160000it [01:42, 1562.99it/s]                                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 155860])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160000it [01:41, 1581.79it/s]                                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n",
      "done\n",
      "torch.Size([5000, 153316])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160000it [00:15, 10166.54it/s]                                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 155860])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160000it [00:19, 8099.97it/s]                                                                                                       \n"
     ]
    }
   ],
   "source": [
    "with open(tmp_path/f'dones.pkl', 'rb') as f:\n",
    "    d = pickle.load(f)\n",
    "    \n",
    "for key in [*keys, 'dones']:\n",
    "    a = None\n",
    "    b = None\n",
    "    \n",
    "    print('loading...')\n",
    "    with open(tmp_path/f'{key}.pkl', 'rb') as f:\n",
    "        a = pickle.load(f)\n",
    "    print('done')\n",
    "    \n",
    "    splits = 2\n",
    "    start = 0\n",
    "    offset = len(a)//splits\n",
    "    ctr = 0\n",
    "    for _ in range(splits):\n",
    "        _, ctr = convert_to_traj_and_save(key, a[start:(start+offset)], d[start:(start+offset)], ctr)\n",
    "        start += offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ddd0c60-7511-40e8-a413-489abce9c7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [1:11:52<00:00, 134.78s/it]\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH_TRAJ = Path(f'/common/users/dm1487/legged_manipulation_data/rollout_data/latest_individual_traj_2')\n",
    "DATA_PATH_TRAJ.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "file_list = {}\n",
    "for key in [*keys, 'dones']:\n",
    "    file_list[key] = sorted(list(glob(f'/common/users/dm1487/legged_manipulation_data/rollout_data/latest_trajectories_2/{key}/*.npz')), \n",
    "                            key= lambda x: int(str(x).split('.npz')[0].split('/')[-1].split('_')[-1]))\n",
    "\n",
    "traj_ctr = 0\n",
    "with tqdm(total=len(list(file_list.values())[0])) as pbar:\n",
    "    for observations, privileged_observations, observation_histories, full_seen_world, dones in zip(*file_list.values()):\n",
    "        obs = np.load(observations)['data']\n",
    "        priv_obs = np.load(privileged_observations)['data']\n",
    "        obs_hist = np.load(observation_histories)['data']\n",
    "        fsw = np.load(full_seen_world)['data']\n",
    "        d = np.load(dones)['data']\n",
    "        for idx in range(obs.shape[0]):\n",
    "            # print(obs_hist[idx].shape, fsw[idx].shape, priv_obs[idx].shape, d[idx][:750].reshape(-1, 1).shape)\n",
    "            np.savez_compressed(DATA_PATH_TRAJ/f'traj_{traj_ctr}', obs=obs[idx], priv_obs=priv_obs[idx], obs_hist=obs_hist[idx][:, -37:], fsw=fsw[idx], done=d[idx][:750].reshape(-1, 1))\n",
    "            traj_ctr += 1\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0602193a-b8b7-43d8-b1f5-a1528890304b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265951"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "123455 + 142496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc1278-9ccd-4ac1-ba04-403c4f1727c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "DATA_PATH_TRAJ = Path(f'/common/users/dm1487/legged_manipulation_data/rollout_data/latest_individual_traj_mini')\n",
    "all_files = os.listdir(DATA_PATH_TRAJ)\n",
    "ignore_files = []\n",
    "for i in tqdm(all_files[:]):\n",
    "    traj = np.load(DATA_PATH_TRAJ/i)\n",
    "    last_idx = traj['done'].nonzero()[0][-1]\n",
    "    if np.sum(traj['fsw'][last_idx][:7]) != 0:\n",
    "        if np.sum(traj['fsw'][last_idx][1:7] == traj['priv_obs'][last_idx][1:7]) != 6:\n",
    "            \n",
    "            ignore_files.append(DATA_PATH_TRAJ/i)\n",
    "            \n",
    "## save ignore_files as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e41823-e65b-4d7d-a670-1cceeadd06c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924ed1a-fd80-4088-84b6-7118bec08132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855cebe1-1a1b-4456-ab1c-7cd126a12223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944232d-e040-4e53-80f2-10b1fb114f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb3a8d-63a1-4c94-b186-428c1fe8b369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f796db-1fc7-45cc-bba3-e9a52ced1510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_obs_traj = split_and_pad_trajectories(all_obs, all_dones)\n",
    "# all_priv_obs_traj = split_and_pad_trajectories(all_priv_obs, all_dones)\n",
    "# all_obs_hist_traj = split_and_pad_trajectories(all_obs_hist, all_dones)\n",
    "# # all_obs_traj = split_and_pad_trajectories(all_obs, all_dones)\n",
    "# all_obs_traj.shape, all_priv_obs_traj.shape, all_obs_hist_traj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2143adf-b4b4-463a-bb9c-2fb6391822ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b1cc32-9ead-4adf-ab2e-2d8a225e92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('/common/users/dm1487/legged_manipulation_data/rollout_data/set_3_trajectories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a730874-5b2d-4309-8b3b-8041bdb0e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_merge = sorted(list((data_path/'obs_hist').glob('*')), key= lambda x: int(str(x).split('.npz')[0].split('_')[-1]))\n",
    "DATA_PATH_TRAJ = Path(f'/common/users/dm1487/legged_manipulation_data/rollout_data/set_3_trajectories/obs_hist_combined')\n",
    "DATA_PATH_TRAJ.mkdir(parents=True, exist_ok=True)\n",
    "# len(files_merge)\n",
    "for i in range(10, len(files_merge), 10):\n",
    "    files_length = 10\n",
    "    if i == 50:\n",
    "        files_length = 9\n",
    "    files = [np.load(files_merge[j+i]) for j in range(files_length)] # np.load(files_merge[i]), np.load(files_merge[i+1])\n",
    "    print(i, len(files))\n",
    "    final_data = np.concatenate([f['data'] for f in files], axis=0)\n",
    "    print(final_data.shape)\n",
    "    np.savez_compressed(DATA_PATH_TRAJ/f'obs_hist_combined_{i}.npz', data=final_data)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e34254-a354-4522-82a7-42aefb49d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = 200000//100000\n",
    "traj_data = {\n",
    "    'obs': None, \n",
    "    'obs_hist_combined': None, \n",
    "    'priv_obs': None, \n",
    "    'mask': None\n",
    "}\n",
    "# while length <= trajectory_length:\n",
    "for i in sorted(data_path.glob('*')):\n",
    "    name = str(i).split('/')[-1] \n",
    "    if  name == 'obs_hist' or name == 'mask1':\n",
    "        continue\n",
    "    print(i)\n",
    "    for j in sorted(glob(f'{i}/*.npz'))[:trajectories]:\n",
    "        if traj_data[name] is None:\n",
    "            traj_data[name] = np.load(j)['data']\n",
    "        else:\n",
    "            traj_data[name] = np.concatenate([traj_data[name], np.load(j)['data']], axis=0)\n",
    "        print(traj_data[name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c8588-1e55-4b00-88f6-c99d210f1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_data['obs_hist_combined'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da2396-bf3e-4248-a87b-5bf1534adc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_path = Path('/common/users/dm1487/legged_manipulation_data/rollout_data/set3_traj_200k')\n",
    "# traj_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137139ee-c9bd-4966-abeb-be3c091f883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez_compressed(traj_path, **traj_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e78113-8c66-47ed-ba40-304559d64424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traj_num = np.random.randint(0, 200000)\n",
    "# print(traj_num)\n",
    "# plt.scatter(traj_data['obs'][traj_num][:, 0], traj_data['obs'][traj_num][:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e7157-c9df-4272-8baa-28ec0200e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = 200000\n",
    "obs_hist = torch.zeros(trajectories, traj_data['obs'].shape[1],  traj_data['obs'].shape[2] + traj_data['obs_hist_combined'].shape[2])\n",
    "obs_hist[:, :, :traj_data['obs'].shape[2]] = torch.tensor(traj_data['obs'])\n",
    "obs_hist[:, :, traj_data['obs'].shape[2]:] = torch.tensor(traj_data['obs_hist_combined'])\n",
    "\n",
    "FILE_NAME = 'rnn_200k_data'\n",
    "DATA_PATH_TRAJ = Path(f'/common/users/dm1487/legged_manipulation_data/rollout_data/set_3_trajectories/{FILE_NAME}')\n",
    "np.savez_compressed(DATA_PATH_TRAJ, inp=obs_hist.numpy(), target=traj_data['priv_obs'], mask=traj_data['mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a0f73-a362-4d65-8078-f47a0b1d0fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DATA_PATH_TRAJ)\n",
    "traj = np.load(DATA_PATH_TRAJ/'traj_3.npz')['obs']\n",
    "plt.scatter(traj[:, 0], traj[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5cc21-30b8-476b-903f-ada6edd2a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ab41b-0534-406e-bd7c-d32746615e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e30869-a50a-46d3-9b0f-ad4e5a2292bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1196c6c-0829-4455-b359-2b260aed17ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63668b07-5ba1-457b-9db2-671f533ad8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f67671-7a9a-4826-bb77-241301b1a288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
